{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.hackerrank.com/challenges/the-missing-characters/problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given a paragraph of text, all in one line. These snippets of text were extracted from articles about people and places, from Wikipedia. Certain letters (a-z or A-Z) have been blanked out and replaced by '#' signs instead. Identify what those letters originally were.\n",
    "\n",
    "Input Format\n",
    "Exactly one line of a text snippet - which may contain either one sentence, or a paragraph (of multiple sentences). At certain positions, letters (a-z or A-Z) have been blanked out and replaced by '#' signs instead.\n",
    "\n",
    "Constraints\n",
    "Number of characters in the input will not exceed 2000.\n",
    "There will be no extra '#' other than those which need to be replaced by letters. Please note that the text may have non-ASCII (UTF-8) characters. However, the the valid replacements for '#' symbols, in all cases, are one of the letters (a-z or A-Z; case agnostic). Characters have been blanked out with approximately 5% probability; i.e. roughly 1 in 20 letters are missing.\n",
    "\n",
    "Output Format\n",
    "The output should contain as many lines as the number of '#' signs in the input text. The ith line should contain the letter of the alphabet which was originally present in place of the ith hash symbol. Evaluation will be case insensitive.\n",
    "\n",
    "Sample Input\n",
    "\n",
    "William Shakespea#e was an Englis# poet, playwright a#d actor, widely regarded as the greatest writer in the Eng#ish langu#ge and the worl#'s pre-eminent dramat#st. He is ofte# called Englan#'s national poet an# the \"Bard of Avon\".  \n",
    "Sample Output\n",
    "\n",
    "r\n",
    "h\n",
    "n\n",
    "l\n",
    "a\n",
    "d\n",
    "i\n",
    "n\n",
    "d\n",
    "d  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus.txt') as f:\n",
    "    corpus = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input00.txt') as f:\n",
    "    input_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'William Shakespea#e was an Englis# poet, playwright a#d actor, widely regarded as the greatest writer in the Eng#ish langu#ge and the worl#\\'s pre-eminent dramat#st. He is ofte# called Englan#\\'s national poet an# the \"Bard of Avon\".\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "# you cannot use the following ones because you will get read of the \"#\"\n",
    "# input_text_tokens = WordPunctTokenizer().tokenize(input_text)\n",
    "input_text_tokens = nltk.regexp_tokenize(input_text, r'''[^ \\!@$%&\\*()\\-_=+\\[\\]{}.,?\\n\\r]+''')\n",
    "corpus_tokens = nltk.regexp_tokenize(corpus, r'''[^ \\!@$%&\\*()\\-_=+\\[\\]{}.,?\\n\\r]+''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shakespea#e',\n",
       " 'Englis#',\n",
       " 'a#d',\n",
       " 'Eng#ish',\n",
       " 'langu#ge',\n",
       " \"worl#'s\",\n",
       " 'dramat#st',\n",
       " 'ofte#',\n",
       " \"Englan#'s\",\n",
       " 'an#']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_words = [input_text_token for input_text_token in input_text_tokens if '#' in input_text_token]\n",
    "missing_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r\n",
      "h\n",
      "l\n",
      "a\n",
      "d\n",
      "i\n",
      "n\n",
      "d\n"
     ]
    }
   ],
   "source": [
    "for missing_word in missing_words:\n",
    "\n",
    "    # n (default 3) is the maximum number of close matches\n",
    "    # cutoff (default 0.6) is a float in the range [0, 1]. \n",
    "    # we want to adjust so as to include lots of matches\n",
    "    \n",
    "    possible_matching_words = difflib.get_close_matches(missing_word, corpus_tokens, 1000,0.1)\n",
    "    for matching_word in possible_matching_words:\n",
    "        if len(missing_word) == len(matching_word):\n",
    "            check = True\n",
    "            for i in range(len(missing_word)):\n",
    "                if missing_word[i] != '#' and missing_word[i] != matching_word[i]:\n",
    "                    check = False\n",
    "            if check:\n",
    "                for i, char in enumerate(missing_word):\n",
    "                    if char == '#':\n",
    "                        print(matching_word[i])                \n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
